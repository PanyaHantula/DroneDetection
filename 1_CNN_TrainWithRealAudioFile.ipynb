{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Classification with CNN model \n",
    "- CNN train with real audio file (1 second time duration). \n",
    "- Using normalize sound between -1 to 1 , noise reduce and calculate spectrogram to train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa # type: ignore\n",
    "import librosa.display # type: ignore\n",
    "import numpy as np # type: ignore\n",
    "\n",
    "# Load example a drone audio file\n",
    "audio_file = 'D:\\\\dataset_drone\\\\Drone\\\\Drone_0.wav'  # Replace with your audio file path\n",
    "y, fs = librosa.load(audio_file)  # , duration=20)\n",
    "timesDuration = librosa.get_duration(y=y, sr=fs)\n",
    "\n",
    "# normalize audio  \n",
    "max_value = np.max(np.abs(y))       # Determine the maximum values\n",
    "audio_Drone = y/max_value           # Use max_value and normalize sound data to get values between -1 & +1\n",
    "\n",
    "print(f'Sampling Rate: {fs} Hz')\n",
    "print(f'Audio Duration: {timesDuration:.0f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio  # type: ignore\n",
    "\n",
    "Audio(data=audio_Drone, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectrogram Calculate \n",
    "Calculate Spectrogram by using SFTF method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Spectrogram by using SFTF method\n",
    "def spectrogram_cal(data,fs):\n",
    "    ms = librosa.feature.melspectrogram(y=data, sr=fs, n_fft=2048, hop_length=128, n_mels=256)\n",
    "    spectrogram_db = librosa.power_to_db(ms, ref=np.max)\n",
    "    \n",
    "    return spectrogram_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FFT Calculate\n",
    "1-D discrete Fourier transforms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fft import fft, fftfreq # type: ignore\n",
    "\n",
    "# ----- 1-D discrete Fourier transforms ------\n",
    "def audioFFT_cal (data,fs):\n",
    "    N = int(fs * timesDuration)         #   Number of sample points\n",
    "\n",
    "    T = 1.0 / (fs)   # sample spacing\n",
    "    x = np.linspace(0.0, N*T, N, endpoint=False)\n",
    "    yf = fft(data)\n",
    "    Xf = fftfreq(N, T)[:N//2]\n",
    "    FFT_Amplitude = 10*np.log(np.abs(yf[0:N//2]))\n",
    "    \n",
    "    return Xf,FFT_Amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot demo of audio graph \n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "\n",
    "y_signal = audio_Drone\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "# ----- Plot Audio Waveform  -----\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title(f'Audio Waveform')\n",
    "plt.plot(np.linspace(0, len(y_signal) / fs, len(y_signal)), y_signal)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.grid()\n",
    "# ----- Plot FFT  -----\n",
    "xf,yf = audioFFT_cal(y_signal,fs)    \n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title(f'FFT waveform')\n",
    "plt.plot(xf, yf)\n",
    "plt.grid()\n",
    "plt.xlabel('Freq (Hz)')\n",
    "plt.ylabel('Normalize Amplitude (dB)')\n",
    "plt.ylim(-50,80)\n",
    "\n",
    "# ------- Plot Spectrogram ---------\n",
    "spectrogram_db = spectrogram_cal(y_signal,fs)\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title(f'Spectrogram')\n",
    "librosa.display.specshow(spectrogram_db, sr=fs, x_axis='time', y_axis='linear', cmap='viridis')\n",
    "#cmap = 'viridis', 'plasma', 'inferno', 'magma', 'cividis'\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title(f'Spectrogram shape {spectrogram_db.shape}')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing\n",
    "- load all sound in directory \n",
    "- normalize sound between -1 to 1 , noise reduce and calculate spectrogram to train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\dataset_drone\\Drone\\Drone_1280.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1281.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1282.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1283.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1284.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1285.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1286.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1287.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1288.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1289.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_129.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1290.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1291.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1292.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1293.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1294.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1295.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1296.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1297.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1298.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1299.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_13.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_130.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1300.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1301.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1302.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1303.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1304.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1305.wav\n",
      "Error audio File: D:\\dataset_drone\\Drone\\Drone_1305.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1306.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1307.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1308.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1309.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_131.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1310.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1311.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1312.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1313.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1314.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1315.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1316.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1317.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1318.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1319.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_132.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1320.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1321.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1322.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1323.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1324.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1325.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1326.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1327.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1328.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1329.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_133.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1330.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1331.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1332.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1333.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1334.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1335.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1336.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1337.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1338.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1339.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_134.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1340.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1341.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1342.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1343.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1344.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1345.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1346.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1347.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1348.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1349.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_135.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1350.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1351.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1352.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1353.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1354.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1355.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1356.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1357.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1358.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1359.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_136.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1360.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1361.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1362.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1363.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1364.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1365.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1366.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1367.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1368.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1369.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_137.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1370.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1371.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1372.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1373.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1374.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1375.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1376.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1377.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1378.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1379.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_138.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1380.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1381.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1382.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1383.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1384.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1385.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1386.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1387.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1388.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1389.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_139.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1390.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1391.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1392.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1393.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1394.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1395.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1396.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1397.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1398.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1399.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_14.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_140.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1400.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1401.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1402.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1403.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1404.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1405.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1406.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1407.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1408.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1409.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_141.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1410.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1411.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1412.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1413.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1414.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1415.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1416.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1417.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1418.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1419.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_142.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1420.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1421.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1422.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1423.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1424.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1425.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1426.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1427.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1428.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1429.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_143.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1430.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1431.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1432.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1433.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1434.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1435.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1436.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1437.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1438.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1439.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_144.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1440.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1441.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1442.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1443.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1444.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1445.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1446.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1447.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1448.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1449.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_145.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1450.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1451.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1452.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1453.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1454.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1455.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1456.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1457.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1458.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1459.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_146.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1460.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1461.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1462.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1463.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1464.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1465.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1466.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1467.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1468.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1469.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_147.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1470.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1471.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1472.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1473.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1474.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1475.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1476.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1477.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1478.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1479.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_148.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1480.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1481.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1482.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1483.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1484.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1485.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1486.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1487.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1488.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1489.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_149.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1490.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1491.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1492.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1493.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1494.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1495.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1496.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1497.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1498.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1499.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_15.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_150.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1500.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1501.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1502.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1503.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1504.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1505.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1506.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1507.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1508.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1509.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_151.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1510.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1511.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1512.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1513.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1514.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1515.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1516.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1517.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1518.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1519.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_152.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1520.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1521.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1522.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1523.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1524.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1525.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1526.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1527.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1528.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1529.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_153.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1530.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1531.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1532.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1533.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1534.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1535.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1536.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1537.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1538.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_1539.wav\n",
      "D:\\dataset_drone\\Drone\\Drone_154.wav\n"
     ]
    }
   ],
   "source": [
    "import noisereduce as nr        # type: ignore\n",
    "from skimage import exposure         # type: ignore\n",
    "\n",
    "# Set the path to dataset folder\n",
    "print(\"#: Set the path to dataset folder\")\n",
    "data_dir = \"D:\\\\dataset_drone\"\n",
    "\n",
    "# parameter config\n",
    "labels = ['Drone','No_Drone']\n",
    "spectrogram_input = []\n",
    "target_labels = []\n",
    "\n",
    "stationary=True\n",
    "prop_decrease=1\n",
    "n_std_thresh_stationary = 1\n",
    "\n",
    "for label in labels:\n",
    "    label_dir = os.path.join(data_dir, label)\n",
    "    for audio_file in os.listdir(label_dir):\n",
    "        audio_path = os.path.join(label_dir, audio_file)\n",
    "        print(audio_path)\n",
    "        \n",
    "        try:\n",
    "            # Import Audio File\n",
    "            audio_original, sr = librosa.load(audio_path)  # Load audio and limit to 3 seconds\n",
    "\n",
    "                    # normalize audio  \n",
    "            max_value = np.max(np.abs(audio_original))       # Determine the maximum values\n",
    "            audio_normalize = audio_original/max_value        # Use max_value and normalize sound data to get values between -1 & +1\n",
    "\n",
    "                    # perform noise reduction\n",
    "            audio_reduced_noise = nr.reduce_noise(y=audio_normalize, \n",
    "                                                sr=fs, \n",
    "                                                stationary=stationary, \n",
    "                                                prop_decrease=prop_decrease,\n",
    "                                                n_std_thresh_stationary=n_std_thresh_stationary)    # ,use_torch=True )\n",
    "\n",
    "            spectrogram = spectrogram_cal(audio_reduced_noise,fs)\n",
    "            #image_adapteq = exposure.equalize_hist((spectrogram))\n",
    "            \n",
    "            # Transpose the spectrogram to have the shape (timesteps, n_mels)\n",
    "            spectrogram_input.append(spectrogram)\n",
    "            target_labels.append(label)\n",
    "            \n",
    "        except:\n",
    "            print(f'Error audio File: {audio_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and load training data \n",
    "- directory : DatasetForTrain\n",
    "- spectrogram_input\n",
    "- target_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save dataset\n",
    "with open('./DatasetForTrain/spectrogram_input', 'wb') as fp:\n",
    "    pickle.dump(spectrogram_input, fp)\n",
    "\n",
    "with open('./DatasetForTrain/target_labels', 'wb') as fp:\n",
    "    pickle.dump(target_labels, fp)\n",
    "\n",
    "with open('./DatasetForTrain/labels', 'wb') as fp:\n",
    "    pickle.dump(labels, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # load dataset\n",
    "# with open ('./DataSetForTrain/spectrogram_input', 'rb') as fp:\n",
    "#     spectrogram_input = pickle.load(fp)\n",
    "\n",
    "# with open ('./DataSetForTrain/target_labels', 'rb') as fp:\n",
    "#     target_labels = pickle.load(fp)\n",
    "\n",
    "# with open ('./DataSetForTrain/labels', 'rb') as fp:\n",
    "#     labels = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Python 3.9 only\n",
    "from tensorflow.keras.utils import to_categorical # type: ignore\n",
    "from sklearn.preprocessing import LabelEncoder # type: ignore\n",
    "\n",
    "print(\"#: Encoding targets and data-splitting\")\n",
    "print(\"labels : \" + str(labels))\n",
    "\n",
    "# Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(target_labels)\n",
    "Y_label = to_categorical(encoded_labels)\n",
    "print(f'Encode target labels : {Y_label[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into train and test sets\n",
    "Convert input data to ndarray and split data to train and test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # type: ignore\n",
    "\n",
    "X = np.array(spectrogram_input)\n",
    "y = np.array(Y_label)\n",
    "X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X,y, train_size =0.9, random_state=42 )\n",
    "\n",
    "# Normalize the data\n",
    "xtrain = xtrain / 255.0\n",
    "xtest = xtest / 255.0\n",
    "\n",
    "print(\"xtrain shape : \" + str(xtrain.shape))\n",
    "print(\"xtest shape : \" + str(xtest.shape))\n",
    "print(\"ytrain shape : \" + str(ytrain.shape))\n",
    "print(\"ytest shape : \" + str(ytest.shape))\n",
    "\n",
    "######## Exploratory data analysis #######\n",
    "# Count the number of samples in each class\n",
    "print()\n",
    "print(\"#: Count the number of samples in each class\")\n",
    "class_counts = [len(os.listdir(os.path.join(data_dir, label))) for label in labels]\n",
    "\n",
    "print(\"Total Data set: \" + str(int(class_counts[0]) + int(class_counts[1])))\n",
    "print(labels[0] + \": \" + str(class_counts[0]))\n",
    "print(labels[1] + \": \" + str(class_counts[1]))\n",
    "print()\n",
    "\n",
    "print(\"Data set for Train: \" + str(xtrain.shape[0]))\n",
    "print(\"Data set for Test: \" + str(xtest.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras # type: ignore\n",
    "import tensorflow as tf\n",
    "\n",
    "# Create the convolutional base\n",
    "model = keras.Sequential([\n",
    "        keras.layers.Conv2D(128, (3,3), activation='relu', input_shape=xtrain.shape[1:]),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        keras.layers.Conv2D(128,(3,3) , activation='relu'),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        keras.layers.Dense(64),\n",
    "        keras.layers.Dense(32),\n",
    "        keras.layers.Dense(16),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(1024, activation='relu'),\n",
    "        keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "# early_stop = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# hist = model.fit(xtrain, \n",
    "#                  ytrain, \n",
    "#                  validation_data=(xtest, ytest), \n",
    "#                  batch_size=32, \n",
    "#                  epochs=50,  \n",
    "#                  callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(xtrain, \n",
    "                 ytrain, \n",
    "                 validation_data=(xtest, ytest), \n",
    "                 batch_size=32, \n",
    "                 epochs=50)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = hist.history['accuracy']\n",
    "val_acc = hist.history['val_accuracy']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, '-', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, ':', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, '-', label='Training loss')\n",
    "plt.plot(epochs, val_loss, ':', label='Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "directory_name = 'model_01'\n",
    "os.mkdir('./model/' + directory_name)\n",
    "\n",
    "metrics = pd.DataFrame(model.history.history)\n",
    "metrics.to_csv('./model/' + directory_name + '/hist.csv', index=False)\n",
    "\n",
    "# save model\n",
    "model.save('./model/' + directory_name + '/myModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "from tensorflow.keras.models import load_model # type: ignore\n",
    "\n",
    "myModel = load_model('./model/' + directory_name + '/myModel.h5') #same file path\n",
    "myModel.summary()\n",
    "\n",
    "loss, acc = myModel.evaluate(xtest, ytest, verbose=0)\n",
    "print(f\"test accuracy {acc*100}\")\n",
    "print(f\"test loss {loss*100}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report , confusion_matrix # type: ignore\n",
    "import seaborn as sns # type: ignore\n",
    "\n",
    "y_predicted = myModel.predict(xtest)\n",
    "mat = confusion_matrix(ytest.argmax(axis=1), y_predicted.argmax(axis=1))\n",
    "class_labels = ['Drone', 'NoDrone']\n",
    "\n",
    "# Calculate accuracy and F1 score\n",
    "print(\"#: Calculate accuracy and F1 score\")\n",
    "accuracy = accuracy_score(ytest.argmax(axis=1), y_predicted.argmax(axis=1))\n",
    "\n",
    "f1 = f1_score(ytest.argmax(axis=1), y_predicted.argmax(axis=1))\n",
    "\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "#print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print('F1 score: {:.2f}'.format(f1))\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(ytest.argmax(axis=1), y_predicted.argmax(axis=1), target_names=class_labels))\n",
    "\n",
    "sns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False, cmap='Blues',\n",
    "            xticklabels=class_labels,\n",
    "            yticklabels=class_labels)\n",
    "\n",
    "plt.title('Confusion Matrix', fontsize=15, pad=20)\n",
    "plt.xlabel('Prediction', fontsize=11)\n",
    "plt.ylabel('Actual', fontsize=11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Python 3.9 only\n",
    "from tensorflow.keras.utils import to_categorical # type: ignore\n",
    "from sklearn.preprocessing import LabelEncoder # type: ignore\n",
    "\n",
    "print(\"#: Encoding targets and data-splitting\")\n",
    "print(\"labels : \" + str(labels))\n",
    "\n",
    "# Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(target_labels)\n",
    "Y_label = to_categorical(encoded_labels)\n",
    "print(f'Encode target labels : {Y_label[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Model \n",
    "Ytest = xtest[1]\n",
    "\n",
    "Ytest = Ytest.reshape(1, Ytest.shape[0], Ytest.shape[1], 1)\n",
    "y_predicted = myModel.predict(Ytest)\n",
    "output =  y_predicted.argmax(axis=1)\n",
    "\n",
    "lable_Output = label_encoder.inverse_transform(output)\n",
    "\n",
    "print(f'Predicted Output : {y_predicted}')\n",
    "print(f'Output Valve : {output}')\n",
    "print(f'Output Lable : {lable_Output}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
